{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3068510",
   "metadata": {},
   "source": [
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "772980a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "#nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09b1dd1",
   "metadata": {},
   "source": [
    "### Read data into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a05e113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Message</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>christmas tree farm picture</td>\n",
       "      <td>message text</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vastar resource inc .</td>\n",
       "      <td>gary production high island large block commen...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>calpine daily gas nomination</td>\n",
       "      <td>calpine daily gas nomination .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>issue</td>\n",
       "      <td>fyi see note already . stella forward stella l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>meter nov allocation</td>\n",
       "      <td>forward lauri allen hou ect pm kimberly vaughn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mcmullen gas</td>\n",
       "      <td>jackie since inlet river plant shut last day f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>meter jan</td>\n",
       "      <td>george need follow jan zero receipt package id...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dun number change</td>\n",
       "      <td>fyi forward gary l payne hou ect pm antoine v ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>king ranch</td>\n",
       "      <td>two field gas difficulty unify system . cage r...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>entex transistion</td>\n",
       "      <td>thanks much memo . would like reiterate suppor...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Subject  \\\n",
       "0   christmas tree farm picture   \n",
       "1         vastar resource inc .   \n",
       "2  calpine daily gas nomination   \n",
       "3                         issue   \n",
       "4          meter nov allocation   \n",
       "5                  mcmullen gas   \n",
       "6                     meter jan   \n",
       "7             dun number change   \n",
       "8                    king ranch   \n",
       "9             entex transistion   \n",
       "\n",
       "                                             Message  label  \n",
       "0                                       message text      0  \n",
       "1  gary production high island large block commen...      0  \n",
       "2                     calpine daily gas nomination .      0  \n",
       "3  fyi see note already . stella forward stella l...      0  \n",
       "4  forward lauri allen hou ect pm kimberly vaughn...      0  \n",
       "5  jackie since inlet river plant shut last day f...      0  \n",
       "6  george need follow jan zero receipt package id...      0  \n",
       "7  fyi forward gary l payne hou ect pm antoine v ...      0  \n",
       "8  two field gas difficulty unify system . cage r...      0  \n",
       "9  thanks much memo . would like reiterate suppor...      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db=pd.read_csv('data/enron_spam_ham_email_clean.csv')\n",
    "db.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7725fc5f",
   "metadata": {},
   "source": [
    "### Define processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "b95ab566",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def regex_processing(msg):\n",
    "    msg=re.sub('[^a-z\\.]',\" \",msg.lower()) #lowercasing and removing every character which is not an alphabet or '.'\n",
    "    msg=re.sub('\\s+',\" \",msg)              #removing extra whitespaces\n",
    "    msg=re.sub('\\.+\\s+\\.',\".\",msg)         #removing double dots to avoid issues during splitting into sentences\n",
    "    return msg\n",
    "\n",
    "def sentence_dropping(msg):\n",
    "    n=2                                    #attempting to drop sentences which don't have more than 2 words in it\n",
    "    tmp=[sent for sent in sent_tokenize(msg) if len(sent.split())>n]\n",
    "    if not tmp:\n",
    "        return msg\n",
    "    return ' '.join(tmp)\n",
    "\n",
    "ref_tag={'NN':'n','NNS':'n','NNP':'n','NNPS':'n',\n",
    "         'VB':'v','VBD':'v','VBG':'v','VBN':'v','VBP':'v','VBZ':'v',\n",
    "         'JJ':'a','JJR':'a','JJS':'a',\n",
    "         'RB':'r','RBR':'r','RBS':'r',\n",
    "         'ADJ_SAT':'s'}\n",
    "\n",
    "stop_words=set(stopwords.words('english'))\n",
    "\n",
    "def lemma(msg,def_txt):\n",
    "    tmp=[]\n",
    "    for sentence in sent_tokenize(sentence_dropping(regex_processing(msg))):\n",
    "        tags=nltk.pos_tag(nltk.word_tokenize(sentence))\n",
    "        lemmatized=' '.join([lemmatizer.lemmatize(word) if ref_tag.get(tag,\"\")==\"\" else lemmatizer.lemmatize(word,ref_tag.get(tag)) for word,tag in tags])\n",
    "        \n",
    "        filtered=lemmatized\n",
    "        tmp_var=' '.join([word for word in word_tokenize(lemmatized) if word not in stop_words])\n",
    "        if len(tmp_var):\n",
    "            filtered=tmp_var\n",
    "            \n",
    "        tmp.append(sentence_dropping(filtered))\n",
    "    \n",
    "    if not len(tmp):\n",
    "        return def_txt\n",
    "    \n",
    "    return ' '.join(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec307a4",
   "metadata": {},
   "source": [
    "### Process 'Subjects' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "22e42e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Elapsed (Subject): 1 m 38 s\n"
     ]
    }
   ],
   "source": [
    "t=time.time()\n",
    "\n",
    "for i in range(len(db['Subject'])):\n",
    "    db.loc[i,'Subject']=lemma(db.loc[i,'Subject'],'subject')\n",
    "    \n",
    "print(f'Total Elapsed (Subject): {(time.time()-t)//60:.0f} m {(time.time()-t)%60:.0f} s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dfebcf",
   "metadata": {},
   "source": [
    "### Process 'Messages' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "73aa892a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Elapsed (Subject): 16 m 26 s\n"
     ]
    }
   ],
   "source": [
    "t=time.time()\n",
    "\n",
    "for i in range(len(db['Message'])):\n",
    "    db.loc[i,'Message']=lemma(db.loc[i,'Message'],'message text')\n",
    "    \n",
    "print(f'Total Elapsed (Message): {(time.time()-t)//60:.0f} m {(time.time()-t)%60:.0f} s')\n",
    "\n",
    "db.to_csv(\"data/enron_spam_ham_email_processed_v2.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
